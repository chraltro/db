# dp — Self-Hosted Data Platform

A lightweight, self-hosted data platform for companies who find Databricks/Snowflake too complex and too expensive. Runs on a single machine. No data leaves your infrastructure.

**DuckDB** for OLAP. **Plain SQL** for transforms. **Python** for ingest/export. **No Jinja**, no compilation step, no profiles.yml.

## Quick Start

```bash
pip install -e .
dp init my-project
cd my-project
dp transform
dp serve
```

## Architecture

```
ingest/           Python scripts that load data into DuckDB
transform/
  bronze/         Light cleanup, type casting, dedup
  silver/         Business logic, joins, conforming
  gold/           Consumption-ready facts and dimensions
export/           Python scripts that export data from DuckDB
warehouse.duckdb  The whole database, one file
project.yml       Streams, schedules, connections
```

## SQL Transform Convention

```sql
-- config: materialized=view, schema=bronze
-- depends_on: landing.customers

SELECT
    customer_id,
    UPPER(name) AS name
FROM landing.customers
```

Config is a comment. SQL is just SQL. No templating.

## Commands

- `dp init <name>` — scaffold a new project
- `dp run <script>` — run an ingest or export script
- `dp transform` — build all SQL models in dependency order
- `dp stream <name>` — run a full pipeline (ingest + transform + export)
- `dp lint` — lint SQL with SQLFluff
- `dp query "<sql>"` — run ad-hoc queries
- `dp tables` — list warehouse objects
- `dp history` — show run history
- `dp serve` — start the web UI
- `dp context` — generate a project summary for any AI chat

## LLM / AI Agent Integration

dp is designed to be easy to use with LLM-powered coding tools. New projects scaffolded with `dp init` include a `CLAUDE.md` file with full agent instructions out of the box.

**Supported tools:**

| Tool | Config file | Included |
|------|------------|----------|
| [Claude Code](https://docs.anthropic.com/en/docs/claude-code) | `CLAUDE.md` | Auto-generated by `dp init` |
| [Cursor](https://cursor.sh) | `.cursorrules` | In repo root |
| [GitHub Copilot](https://github.com/features/copilot) | `.github/copilot-instructions.md` | In repo root |
| Any LLM (ChatGPT, Claude, etc.) | `dp context` | Run command, paste output |

**Using with any AI chat (no code editor needed):**

```bash
dp context
# Copy the output, paste into ChatGPT/Claude/any AI chat, then ask your question
```

**Why this works well with LLMs:**

- **Plain SQL** — no Jinja templating or DSLs; LLMs write standard SQL directly
- **Simple contracts** — Python scripts just need a `run(db)` function
- **Comment-based config** — `-- config:` and `-- depends_on:` are easy for LLMs to read and write
- **Single-file database** — no infrastructure to manage, no connection strings to debug
- **CLI-first** — every operation has a CLI command that agents can call directly
- **Self-contained tests** — `pytest tests/` runs with no external dependencies

**Example prompts that work well:**

> "Load CSV files from data/customers.csv into the warehouse"

> "Create a gold table that shows monthly revenue by product"

> "Why did the last pipeline run fail?"

> "Add a new ingest script that pulls data from our Postgres database"

The LLM can follow the conventions in `CLAUDE.md` to create the right files in the right places, with the right SQL comment headers, and verify everything works with `dp transform` and `dp query`.
